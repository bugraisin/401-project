{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c7ab08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/20 13:21:30 WARN Utils: Your hostname, bugra-Zenbook-UX3402ZA-UX3402ZA resolves to a loopback address: 127.0.1.1; using 192.168.1.132 instead (on interface wlo1)\n",
      "25/07/20 13:21:30 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/20 13:21:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/07/20 13:21:32 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col, to_timestamp, unix_timestamp\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"US Accidents Severity Prediction\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"50\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.8\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb149262",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9d0a7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------------+------------------+------------------+------------+--------------------+------------+-----+-------------------+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+--------+--------+---------------+--------------+------------+--------------+--------------+\n",
      "|Severity|         Start_Time|           End_Time|         Start_Lat|         Start_Lng|Distance(mi)|              Street|        City|State|  Weather_Timestamp|Temperature(F)|Wind_Chill(F)|Humidity(%)|Pressure(in)|Visibility(mi)|Wind_Direction|Wind_Speed(mph)|Weather_Condition|Crossing|Junction|Traffic_Calming|Traffic_Signal|Turning_Loop|Sunrise_Sunset|Civil_Twilight|\n",
      "+--------+-------------------+-------------------+------------------+------------------+------------+--------------------+------------+-----+-------------------+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+--------+--------+---------------+--------------+------------+--------------+--------------+\n",
      "|       3|2016-02-08 05:46:00|2016-02-08 11:00:00|         39.865147|        -84.058723|        0.01|              I-70 E|      Dayton|   OH|2016-02-08 05:58:00|          36.9|         NULL|       91.0|       29.68|          10.0|          Calm|           NULL|       Light Rain|   false|   false|          false|         false|       false|         Night|         Night|\n",
      "|       2|2016-02-08 06:07:59|2016-02-08 06:37:59| 39.92805900000001|        -82.831184|        0.01|            Brice Rd|Reynoldsburg|   OH|2016-02-08 05:51:00|          37.9|         NULL|      100.0|       29.65|          10.0|          Calm|           NULL|       Light Rain|   false|   false|          false|         false|       false|         Night|         Night|\n",
      "|       2|2016-02-08 06:49:27|2016-02-08 07:19:27|         39.063148|        -84.032608|        0.01|      State Route 32|Williamsburg|   OH|2016-02-08 06:56:00|          36.0|         33.3|      100.0|       29.67|          10.0|            SW|            3.5|         Overcast|   false|   false|          false|          true|       false|         Night|         Night|\n",
      "|       3|2016-02-08 07:23:34|2016-02-08 07:53:34|         39.747753|-84.20558199999998|        0.01|              I-75 S|      Dayton|   OH|2016-02-08 07:38:00|          35.1|         31.0|       96.0|       29.64|           9.0|            SW|            4.6|    Mostly Cloudy|   false|   false|          false|         false|       false|         Night|           Day|\n",
      "|       2|2016-02-08 07:39:07|2016-02-08 08:09:07|         39.627781|        -84.188354|        0.01|Miamisburg Center...|      Dayton|   OH|2016-02-08 07:53:00|          36.0|         33.3|       89.0|       29.65|           6.0|            SW|            3.5|    Mostly Cloudy|   false|   false|          false|          true|       false|           Day|           Day|\n",
      "|       3|2016-02-08 07:44:26|2016-02-08 08:14:26|40.100590000000004|-82.92519399999998|        0.01|      Westerville Rd| Westerville|   OH|2016-02-08 07:51:00|          37.9|         35.5|       97.0|       29.63|           7.0|           SSW|            3.5|       Light Rain|   false|   false|          false|         false|       false|           Day|           Day|\n",
      "|       2|2016-02-08 07:59:35|2016-02-08 08:29:35|         39.758274|-84.23050699999997|         0.0|      N Woodward Ave|      Dayton|   OH|2016-02-08 07:56:00|          34.0|         31.0|      100.0|       29.66|           7.0|           WSW|            3.5|         Overcast|   false|   false|          false|         false|       false|           Day|           Day|\n",
      "|       3|2016-02-08 07:59:58|2016-02-08 08:29:58|         39.770382|        -84.194901|        0.01|           N Main St|      Dayton|   OH|2016-02-08 07:56:00|          34.0|         31.0|      100.0|       29.66|           7.0|           WSW|            3.5|         Overcast|   false|   false|          false|         false|       false|           Day|           Day|\n",
      "|       2|2016-02-08 08:00:40|2016-02-08 08:30:40|         39.778061|        -84.172005|         0.0|      Notre Dame Ave|      Dayton|   OH|2016-02-08 07:58:00|          33.3|         NULL|       99.0|       29.67|           5.0|            SW|            1.2|    Mostly Cloudy|   false|   false|          false|         false|       false|           Day|           Day|\n",
      "|       3|2016-02-08 08:10:04|2016-02-08 08:40:04|40.100590000000004|-82.92519399999998|        0.01|      Westerville Rd| Westerville|   OH|2016-02-08 08:28:00|          37.4|         33.8|      100.0|       29.62|           3.0|           SSW|            4.6|       Light Rain|   false|   false|          false|         false|       false|           Day|           Day|\n",
      "|       3|2016-02-08 08:14:42|2016-02-08 08:44:42|         39.952812|        -83.119293|        0.01|         Outerbelt S|    Columbus|   OH|2016-02-08 07:50:00|          35.6|         30.7|       93.0|       29.64|           5.0|           WNW|            5.8|             Rain|    true|    true|          false|         false|       false|           Day|           Day|\n",
      "|       3|2016-02-08 08:21:27|2016-02-08 08:51:27|         39.932709|         -82.83091|        0.01|              I-70 E|Reynoldsburg|   OH|2016-02-08 08:28:00|          37.4|         33.8|      100.0|       29.62|           3.0|           SSW|            4.6|       Light Rain|   false|   false|          false|         false|       false|           Day|           Day|\n",
      "|       2|2016-02-08 08:36:34|2016-02-08 09:06:34|         39.737633|-84.14993299999998|         0.0|      Watervliet Ave|      Dayton|   OH|2016-02-08 08:28:00|          33.8|         NULL|      100.0|       29.63|           3.0|            SW|            2.3|         Overcast|   false|   false|          false|         false|       false|           Day|           Day|\n",
      "|       2|2016-02-08 08:37:07|2016-02-08 09:07:07|          39.79076|        -84.241547|        0.01|           Salem Ave|      Dayton|   OH|2016-02-08 08:56:00|          36.0|         31.1|       89.0|       29.65|          10.0|            NW|            5.8|    Mostly Cloudy|   false|   false|          false|          true|       false|           Day|           Day|\n",
      "|       2|2016-02-08 08:39:43|2016-02-08 09:09:43|         39.972038|        -82.913521|        0.01|          E Broad St|    Columbus|   OH|2016-02-08 08:28:00|          37.4|         33.8|      100.0|       29.62|           3.0|           SSW|            4.6|       Light Rain|   false|   false|          false|          true|       false|           Day|           Day|\n",
      "|       2|2016-02-08 08:43:20|2016-02-08 09:13:20|         39.745888|         -84.17041|        0.01|         Glencoe Ave|      Dayton|   OH|2016-02-08 08:28:00|          33.8|         NULL|      100.0|       29.63|           3.0|            SW|            2.3|         Overcast|   false|   false|          false|         false|       false|           Day|           Day|\n",
      "|       2|2016-02-08 08:53:17|2016-02-08 09:23:17|         39.748329|        -84.224007|        0.01|S James H McGee Blvd|      Dayton|   OH|2016-02-08 08:58:00|          35.6|         NULL|       99.0|       29.65|           7.0|           WSW|            2.3|    Mostly Cloudy|   false|   false|          false|         false|       false|           Day|           Day|\n",
      "|       2|2016-02-08 09:24:37|2016-02-08 09:54:37|         39.752174|        -84.239952|         0.0|         Delphos Ave|      Dayton|   OH|2016-02-08 08:56:00|          36.0|         31.1|       89.0|       29.65|          10.0|            NW|            5.8|    Mostly Cloudy|   false|   false|          false|         false|       false|           Day|           Day|\n",
      "|       2|2016-02-08 09:25:17|2016-02-08 09:55:17|         39.740669|        -84.184135|        0.01|          Rubicon St|      Dayton|   OH|2016-02-08 09:38:00|          37.4|         32.1|       93.0|       29.63|          10.0|           WSW|            6.9|         Overcast|    true|   false|          false|          true|       false|           Day|           Day|\n",
      "|       2|2016-02-08 09:35:35|2016-02-08 10:05:35|         39.790703|        -84.244461|        0.01|     W Hillcrest Ave|      Dayton|   OH|2016-02-08 09:56:00|          36.0|         30.3|       89.0|       29.65|          10.0|          West|            6.9|    Mostly Cloudy|   false|   false|          false|         false|       false|           Day|           Day|\n",
      "+--------+-------------------+-------------------+------------------+------------------+------------+--------------------+------------+-----+-------------------+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+--------+--------+---------------+--------------+------------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df \\\n",
    "    .drop(\"ID\",\"Source\", \"Zipcode\", \"Timezone\", \"Airport_Code\", \"Amenity\", \"End_Lat\", \"End_Lng\",\n",
    "          \"Bump\", \"Give_Way\", \"No_Exit\", \"Railway\", \"Description\", \"County\", \"Precipitation(in)\",\n",
    "          \"Roundabout\", \"Station\", \"Stop\", \"Nautical_Twilight\", \"Astronomical_Twilight\", \"Country\")\n",
    "          \n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0207b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:=====================================================>  (22 + 1) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather_Condition: 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Weather_Condition: \" + str(df2.select(col(\"Weather_Condition\")).distinct().count()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96f4d6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comprehensive column analysis...\n",
      "================================================================================\n",
      "COMPREHENSIVE COLUMN ANALYSIS\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows in DataFrame: 7,728,394\n",
      "\n",
      "\n",
      "📊 ANALYZING: Wind_Chill(F)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type: double\n",
      "Total Values: 7,728,394\n",
      "Distinct Values: 1,002\n",
      "Null Values: 1,999,019 (25.87%)\n",
      "Non-Null Values: 5,729,375 (74.13%)\n",
      "Uniqueness: 0.02%\n",
      "📈 NUMERICAL ANALYSIS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Min: -89.0\n",
      "  Max: 207.0\n",
      "  Mean: 58.25104839533092\n",
      "  Std Dev: 22.3898317496207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  25th Percentile: 43.0\n",
      "  Median (50th): 62.0\n",
      "  75th Percentile: 75.0\n",
      "\n",
      "\n",
      "📊 ANALYZING: Humidity(%)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type: double\n",
      "Total Values: 7,728,394\n",
      "Distinct Values: 101\n",
      "Null Values: 174,144 (2.25%)\n",
      "Non-Null Values: 7,554,250 (97.75%)\n",
      "Uniqueness: 0.00%\n",
      "📈 NUMERICAL ANALYSIS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Min: 1.0\n",
      "  Max: 100.0\n",
      "  Mean: 64.83104146672403\n",
      "  Std Dev: 22.820967660113475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  25th Percentile: 48.0\n",
      "  Median (50th): 67.0\n",
      "  75th Percentile: 84.0\n",
      "\n",
      "\n",
      "📊 ANALYZING: Pressure(in)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type: double\n",
      "Total Values: 7,728,394\n",
      "Distinct Values: 1,145\n",
      "Null Values: 140,679 (1.82%)\n",
      "Non-Null Values: 7,587,715 (98.18%)\n",
      "Uniqueness: 0.02%\n",
      "📈 NUMERICAL ANALYSIS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Min: 0.0\n",
      "  Max: 58.63\n",
      "  Mean: 29.538985607656194\n",
      "  Std Dev: 1.00618980914562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  25th Percentile: 29.36\n",
      "  Median (50th): 29.86\n",
      "  75th Percentile: 30.03\n",
      "\n",
      "\n",
      "📊 ANALYZING: Visibility(mi)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type: double\n",
      "Total Values: 7,728,394\n",
      "Distinct Values: 93\n",
      "Null Values: 177,098 (2.29%)\n",
      "Non-Null Values: 7,551,296 (97.71%)\n",
      "Uniqueness: 0.00%\n",
      "📈 NUMERICAL ANALYSIS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Min: 0.0\n",
      "  Max: 140.0\n",
      "  Mean: 9.090376447963413\n",
      "  Std Dev: 2.68831592141714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  25th Percentile: 10.0\n",
      "  Median (50th): 10.0\n",
      "  75th Percentile: 10.0\n",
      "\n",
      "\n",
      "📊 ANALYZING: Wind_Direction\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type: string\n",
      "Total Values: 7,728,394\n",
      "Distinct Values: 25\n",
      "Null Values: 175,206 (2.27%)\n",
      "Non-Null Values: 7,553,188 (97.73%)\n",
      "Uniqueness: 0.00%\n",
      "📋 CATEGORICAL ANALYSIS:\n",
      "  Top 10 Most Frequent Values:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1. 'CALM': 961,624 (12.44%)\n",
      "     2. 'S': 419,989 (5.43%)\n",
      "     3. 'SSW': 384,840 (4.98%)\n",
      "     4. 'W': 383,913 (4.97%)\n",
      "     5. 'WNW': 378,781 (4.90%)\n",
      "     6. 'NW': 369,352 (4.78%)\n",
      "     7. 'Calm': 368,557 (4.77%)\n",
      "     8. 'SW': 364,470 (4.72%)\n",
      "     9. 'WSW': 353,806 (4.58%)\n",
      "    10. 'SSE': 349,110 (4.52%)\n",
      "\n",
      "\n",
      "📊 ANALYZING: Wind_Speed(mph)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type: double\n",
      "Total Values: 7,728,394\n",
      "Distinct Values: 185\n",
      "Null Values: 571,233 (7.39%)\n",
      "Non-Null Values: 7,157,161 (92.61%)\n",
      "Uniqueness: 0.00%\n",
      "📈 NUMERICAL ANALYSIS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Min: 0.0\n",
      "  Max: 1087.0\n",
      "  Mean: 7.685489595665597\n",
      "  Std Dev: 5.424983437161068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  25th Percentile: 4.6\n",
      "  Median (50th): 7.0\n",
      "  75th Percentile: 10.4\n",
      "\n",
      "\n",
      "📊 ANALYZING: Weather_Condition\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type: string\n",
      "Total Values: 7,728,394\n",
      "Distinct Values: 145\n",
      "Null Values: 173,459 (2.24%)\n",
      "Non-Null Values: 7,554,935 (97.76%)\n",
      "Uniqueness: 0.00%\n",
      "📋 CATEGORICAL ANALYSIS:\n",
      "  Top 10 Most Frequent Values:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1. 'Fair': 2,560,802 (33.13%)\n",
      "     2. 'Mostly Cloudy': 1,016,195 (13.15%)\n",
      "     3. 'Cloudy': 817,082 (10.57%)\n",
      "     4. 'Clear': 808,743 (10.46%)\n",
      "     5. 'Partly Cloudy': 698,972 (9.04%)\n",
      "     6. 'Overcast': 382,866 (4.95%)\n",
      "     7. 'Light Rain': 352,957 (4.57%)\n",
      "     8. 'Scattered Clouds': 204,829 (2.65%)\n",
      "     9. 'NULL': 173,459 (2.24%)\n",
      "    10. 'Light Snow': 128,680 (1.67%)\n",
      "\n",
      "\n",
      "📊 ANALYZING: Crossing\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type: boolean\n",
      "Total Values: 7,728,394\n",
      "Distinct Values: 2\n",
      "Null Values: 0 (0.00%)\n",
      "Non-Null Values: 7,728,394 (100.00%)\n",
      "Uniqueness: 0.00%\n",
      "📋 CATEGORICAL ANALYSIS:\n",
      "  Top 10 Most Frequent Values:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1. 'False': 6,854,631 (88.69%)\n",
      "     2. 'True': 873,763 (11.31%)\n",
      "\n",
      "\n",
      "📊 ANALYZING: Junction\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type: boolean\n",
      "Total Values: 7,728,394\n",
      "Distinct Values: 2\n",
      "Null Values: 0 (0.00%)\n",
      "Non-Null Values: 7,728,394 (100.00%)\n",
      "Uniqueness: 0.00%\n",
      "📋 CATEGORICAL ANALYSIS:\n",
      "  Top 10 Most Frequent Values:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1. 'False': 7,157,052 (92.61%)\n",
      "     2. 'True': 571,342 (7.39%)\n",
      "\n",
      "\n",
      "📊 ANALYZING: Traffic_Calming\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type: boolean\n",
      "Total Values: 7,728,394\n",
      "Distinct Values: 2\n",
      "Null Values: 0 (0.00%)\n",
      "Non-Null Values: 7,728,394 (100.00%)\n",
      "Uniqueness: 0.00%\n",
      "📋 CATEGORICAL ANALYSIS:\n",
      "  Top 10 Most Frequent Values:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1. 'False': 7,720,796 (99.90%)\n",
      "     2. 'True': 7,598 (0.10%)\n",
      "\n",
      "\n",
      "📊 ANALYZING: Traffic_Signal\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type: boolean\n",
      "Total Values: 7,728,394\n",
      "Distinct Values: 2\n",
      "Null Values: 0 (0.00%)\n",
      "Non-Null Values: 7,728,394 (100.00%)\n",
      "Uniqueness: 0.00%\n",
      "📋 CATEGORICAL ANALYSIS:\n",
      "  Top 10 Most Frequent Values:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1. 'False': 6,584,622 (85.20%)\n",
      "     2. 'True': 1,143,772 (14.80%)\n",
      "\n",
      "\n",
      "📊 ANALYZING: Turning_Loop\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type: boolean\n",
      "Total Values: 7,728,394\n",
      "Distinct Values: 1\n",
      "Null Values: 0 (0.00%)\n",
      "Non-Null Values: 7,728,394 (100.00%)\n",
      "Uniqueness: 0.00%\n",
      "📋 CATEGORICAL ANALYSIS:\n",
      "  Top 10 Most Frequent Values:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1. 'False': 7,728,394 (100.00%)\n",
      "\n",
      "\n",
      "📊 ANALYZING: Sunrise_Sunset\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type: string\n",
      "Total Values: 7,728,394\n",
      "Distinct Values: 3\n",
      "Null Values: 23,246 (0.30%)\n",
      "Non-Null Values: 7,705,148 (99.70%)\n",
      "Uniqueness: 0.00%\n",
      "📋 CATEGORICAL ANALYSIS:\n",
      "  Top 10 Most Frequent Values:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1. 'Day': 5,334,553 (69.03%)\n",
      "     2. 'Night': 2,370,595 (30.67%)\n",
      "     3. 'NULL': 23,246 (0.30%)\n",
      "\n",
      "\n",
      "📊 ANALYZING: Civil_Twilight\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type: string\n",
      "Total Values: 7,728,394\n",
      "Distinct Values: 3\n",
      "Null Values: 23,246 (0.30%)\n",
      "Non-Null Values: 7,705,148 (99.70%)\n",
      "Uniqueness: 0.00%\n",
      "📋 CATEGORICAL ANALYSIS:\n",
      "  Top 10 Most Frequent Values:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1. 'Day': 5,695,619 (73.70%)\n",
      "     2. 'Night': 2,009,529 (26.00%)\n",
      "     3. 'NULL': 23,246 (0.30%)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "SUMMARY TABLE\n",
      "================================================================================\n",
      "Column               Type       Distinct   Nulls    Null%    Uniqueness% \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "max() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 132\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# Run the analysis\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting comprehensive column analysis...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 132\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_dataframe_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns_to_analyze\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Additional specific queries you might want\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m)\n",
      "Cell \u001b[0;32mIn[22], line 116\u001b[0m, in \u001b[0;36manalyze_dataframe_columns\u001b[0;34m(df, columns_to_analyze)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m analysis_results:\n\u001b[0;32m--> 116\u001b[0m     uniqueness \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistinct\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtotal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnulls\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m-\u001b[39minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnulls\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<20\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistinct\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<10,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnulls\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<8,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnull_pct\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<8.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muniqueness\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<12\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m analysis_results\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/utils.py:174\u001b[0m, in \u001b[0;36mtry_remote_functions.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(functions, f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: max() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Comprehensive Column Analysis Function\n",
    "def analyze_dataframe_columns(df, columns_to_analyze=None):\n",
    "    \"\"\"\n",
    "    Comprehensive analysis of DataFrame columns\n",
    "    \"\"\"\n",
    "    if columns_to_analyze is None:\n",
    "        columns_to_analyze = df.columns\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"COMPREHENSIVE COLUMN ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    total_rows = df.count()\n",
    "    print(f\"Total Rows in DataFrame: {total_rows:,}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Results storage\n",
    "    analysis_results = []\n",
    "    \n",
    "    for col_name in columns_to_analyze:\n",
    "        print(f\"📊 ANALYZING: {col_name}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        try:\n",
    "            # Get column data type\n",
    "            col_type = dict(df.dtypes)[col_name]\n",
    "            \n",
    "            # Basic statistics\n",
    "            distinct_count = df.select(col(col_name)).distinct().count()\n",
    "            null_count = df.filter(col(col_name).isNull()).count()\n",
    "            non_null_count = total_rows - null_count\n",
    "            null_percentage = (null_count / total_rows) * 100\n",
    "            \n",
    "            print(f\"Data Type: {col_type}\")\n",
    "            print(f\"Total Values: {total_rows:,}\")\n",
    "            print(f\"Distinct Values: {distinct_count:,}\")\n",
    "            print(f\"Null Values: {null_count:,} ({null_percentage:.2f}%)\")\n",
    "            print(f\"Non-Null Values: {non_null_count:,} ({100-null_percentage:.2f}%)\")\n",
    "            print(f\"Uniqueness: {(distinct_count/non_null_count)*100:.2f}%\" if non_null_count > 0 else \"N/A\")\n",
    "            \n",
    "            # Store basic info\n",
    "            col_info = {\n",
    "                'column': col_name,\n",
    "                'type': col_type,\n",
    "                'total': total_rows,\n",
    "                'distinct': distinct_count,\n",
    "                'nulls': null_count,\n",
    "                'null_pct': null_percentage\n",
    "            }\n",
    "            \n",
    "            # Type-specific analysis\n",
    "            if col_type in ['double', 'float', 'int', 'bigint']:\n",
    "                # Numerical column analysis\n",
    "                print(f\"📈 NUMERICAL ANALYSIS:\")\n",
    "                \n",
    "                stats = df.select(col_name).describe().collect()\n",
    "                stats_dict = {row['summary']: row[col_name] for row in stats}\n",
    "                \n",
    "                print(f\"  Min: {stats_dict.get('min', 'N/A')}\")\n",
    "                print(f\"  Max: {stats_dict.get('max', 'N/A')}\")\n",
    "                print(f\"  Mean: {stats_dict.get('mean', 'N/A')}\")\n",
    "                print(f\"  Std Dev: {stats_dict.get('stddev', 'N/A')}\")\n",
    "                \n",
    "                # Quantiles\n",
    "                if non_null_count > 0:\n",
    "                    quantiles = df.select(col_name).approxQuantile(col_name, [0.25, 0.5, 0.75], 0.01)\n",
    "                    if quantiles and len(quantiles) >= 3:\n",
    "                        print(f\"  25th Percentile: {quantiles[0]}\")\n",
    "                        print(f\"  Median (50th): {quantiles[1]}\")\n",
    "                        print(f\"  75th Percentile: {quantiles[2]}\")\n",
    "                \n",
    "                col_info.update({\n",
    "                    'min': stats_dict.get('min'),\n",
    "                    'max': stats_dict.get('max'),\n",
    "                    'mean': stats_dict.get('mean'),\n",
    "                    'std': stats_dict.get('stddev')\n",
    "                })\n",
    "                \n",
    "            else:\n",
    "                # Categorical column analysis\n",
    "                print(f\"📋 CATEGORICAL ANALYSIS:\")\n",
    "                \n",
    "                # Most frequent values\n",
    "                top_values = df.groupBy(col_name).count().orderBy(col(\"count\").desc()).limit(10)\n",
    "                print(f\"  Top 10 Most Frequent Values:\")\n",
    "                \n",
    "                top_values_list = top_values.collect()\n",
    "                for i, row in enumerate(top_values_list, 1):\n",
    "                    value = row[col_name] if row[col_name] is not None else \"NULL\"\n",
    "                    count = row['count']\n",
    "                    percentage = (count / total_rows) * 100\n",
    "                    print(f\"    {i:2d}. '{value}': {count:,} ({percentage:.2f}%)\")\n",
    "                \n",
    "                # Store top value info\n",
    "                if top_values_list:\n",
    "                    col_info['top_value'] = str(top_values_list[0][col_name])\n",
    "                    col_info['top_value_count'] = top_values_list[0]['count']\n",
    "                    col_info['top_value_pct'] = (top_values_list[0]['count'] / total_rows) * 100\n",
    "            \n",
    "            analysis_results.append(col_info)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error analyzing column {col_name}: {str(e)}\")\n",
    "            print(\"\\n\")\n",
    "    \n",
    "    # Summary table\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SUMMARY TABLE\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'Column':<20} {'Type':<10} {'Distinct':<10} {'Nulls':<8} {'Null%':<8} {'Uniqueness%':<12}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for info in analysis_results:\n",
    "        uniqueness = f\"{(info['distinct']/max(info['total']-info['nulls'], 1))*100:.1f}%\" if info['total']-info['nulls'] > 0 else \"N/A\"\n",
    "        print(f\"{info['column']:<20} {info['type']:<10} {info['distinct']:<10,} {info['nulls']:<8,} {info['null_pct']:<8.1f} {uniqueness:<12}\")\n",
    "    \n",
    "    return analysis_results\n",
    "\n",
    "# %%\n",
    "# Specify your columns to analyze\n",
    "columns_to_analyze = [\n",
    "    \"Wind_Chill(F)\", \"Humidity(%)\", \"Pressure(in)\", \"Visibility(mi)\", \n",
    "    \"Wind_Direction\", \"Wind_Speed(mph)\", \"Weather_Condition\", \"Crossing\", \n",
    "    \"Junction\", \"Traffic_Calming\", \"Traffic_Signal\", \"Turning_Loop\", \n",
    "    \"Sunrise_Sunset\", \"Civil_Twilight\"\n",
    "]\n",
    "\n",
    "# Run the analysis\n",
    "print(\"Starting comprehensive column analysis...\")\n",
    "results = analyze_dataframe_columns(df2, columns_to_analyze)\n",
    "\n",
    "# %%\n",
    "# Additional specific queries you might want\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SPECIFIC COLUMN INSIGHTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Boolean columns analysis\n",
    "boolean_cols = [\"Crossing\", \"Junction\", \"Traffic_Calming\", \"Traffic_Signal\", \"Turning_Loop\"]\n",
    "print(\"\\n🔍 BOOLEAN COLUMNS DISTRIBUTION:\")\n",
    "for col_name in boolean_cols:\n",
    "    if col_name in df2.columns:\n",
    "        true_count = df2.filter(col(col_name) == True).count()\n",
    "        false_count = df2.filter(col(col_name) == False).count()\n",
    "        total = true_count + false_count\n",
    "        if total > 0:\n",
    "            print(f\"{col_name}:\")\n",
    "            print(f\"  True: {true_count:,} ({(true_count/total)*100:.1f}%)\")\n",
    "            print(f\"  False: {false_count:,} ({(false_count/total)*100:.1f}%)\")\n",
    "\n",
    "# Weather conditions detailed analysis\n",
    "print(\"\\n🌤️ WEATHER CONDITIONS DETAILED:\")\n",
    "if \"Weather_Condition\" in df2.columns:\n",
    "    weather_stats = df2.groupBy(\"Weather_Condition\").count().orderBy(col(\"count\").desc())\n",
    "    weather_stats.show(20, truncate=False)\n",
    "\n",
    "# Wind direction analysis\n",
    "print(\"\\n💨 WIND DIRECTION DISTRIBUTION:\")\n",
    "if \"Wind_Direction\" in df2.columns:\n",
    "    wind_stats = df2.groupBy(\"Wind_Direction\").count().orderBy(col(\"count\").desc())\n",
    "    wind_stats.show(20, truncate=False)\n",
    "\n",
    "# %%\n",
    "# Quick overview function for any column\n",
    "def quick_column_overview(df, col_name):\n",
    "    \"\"\"Quick overview of a single column\"\"\"\n",
    "    print(f\"\\n🔎 QUICK OVERVIEW: {col_name}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if col_name not in df.columns:\n",
    "        print(f\"❌ Column '{col_name}' not found!\")\n",
    "        return\n",
    "    \n",
    "    total = df.count()\n",
    "    distinct = df.select(col_name).distinct().count()\n",
    "    nulls = df.filter(col(col_name).isNull()).count()\n",
    "    \n",
    "    print(f\"Total rows: {total:,}\")\n",
    "    print(f\"Distinct values: {distinct:,}\")\n",
    "    print(f\"Null values: {nulls:,} ({(nulls/total)*100:.1f}%)\")\n",
    "    print(f\"Data type: {dict(df.dtypes)[col_name]}\")\n",
    "    \n",
    "    # Show sample values\n",
    "    print(\"Sample values:\")\n",
    "    df.select(col_name).distinct().limit(5).show(truncate=False)\n",
    "\n",
    "# Example usage:\n",
    "# quick_column_overview(df2, \"Weather_Condition\")\n",
    "# quick_column_overview(df2, \"Wind_Speed(mph)\")\n",
    "\n",
    "print(\"\\n✅ Analysis completed! Use quick_column_overview(df2, 'column_name') for individual column details.\")\n",
    "\n",
    "columns_to_analyze = [\n",
    "    \"Wind_Chill(F)\", \"Humidity(%)\", \"Pressure(in)\", \"Visibility(mi)\", \n",
    "    \"Wind_Direction\", \"Wind_Speed(mph)\", \"Weather_Condition\", \"Crossing\", \n",
    "    \"Junction\", \"Traffic_Signal\", \"Sunrise_Sunset\", \"Civil_Twilight\"\n",
    "]\n",
    "\n",
    "# Analizi çalıştır\n",
    "print(\"Analiz başlıyor...\")\n",
    "results = analyze_dataframe_columns(df2, columns_to_analyze)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
